<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Passion Driven Statistics</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="<a href="http://www.wesleyan.edu/qac/curriculum/resources/index.html">Passion Driven Statistics</a>">
  <meta name="generator" content="bookdown 0.0.77 and GitBook 2.6.7">

  <meta property="og:title" content="Passion Driven Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Passion Driven Statistics" />
  
  
  

<meta name="author" content="Modified for use with R, GitHub, and Zotero">


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="graphing-relationships.html">
<link rel="next" href="analysis-of-variance.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="./CSS/style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>1</b> Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="overview.html"><a href="overview.html#resources"><i class="fa fa-check"></i><b>1.1</b> Resources</a></li>
<li class="chapter" data-level="1.2" data-path="overview.html"><a href="overview.html#an-introduction-to-statistics"><i class="fa fa-check"></i><b>1.2</b> An Introduction to Statistics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-sets.html"><a href="data-sets.html"><i class="fa fa-check"></i><b>2</b> Data Sets</a></li>
<li class="chapter" data-level="3" data-path="data-architecture.html"><a href="data-architecture.html"><i class="fa fa-check"></i><b>3</b> Data Architecture</a></li>
<li class="chapter" data-level="4" data-path="conducting-a-literature-review.html"><a href="conducting-a-literature-review.html"><i class="fa fa-check"></i><b>4</b> Conducting a Literature Review</a></li>
<li class="chapter" data-level="5" data-path="writing-about-empirical-research.html"><a href="writing-about-empirical-research.html"><i class="fa fa-check"></i><b>5</b> Writing About Empirical Research</a></li>
<li class="chapter" data-level="6" data-path="working-with-data.html"><a href="working-with-data.html"><i class="fa fa-check"></i><b>6</b> Working with Data</a></li>
<li class="chapter" data-level="7" data-path="data-management.html"><a href="data-management.html"><i class="fa fa-check"></i><b>7</b> Data Management</a></li>
<li class="chapter" data-level="8" data-path="graphing-one-variable-at-a-time.html"><a href="graphing-one-variable-at-a-time.html"><i class="fa fa-check"></i><b>8</b> Graphing: One Variable at a Time</a><ul>
<li class="chapter" data-level="8.1" data-path="graphing-one-variable-at-a-time.html"><a href="graphing-one-variable-at-a-time.html#symmetric-distributions"><i class="fa fa-check"></i><b>8.1</b> Symmetric Distributions</a></li>
<li class="chapter" data-level="8.2" data-path="graphing-one-variable-at-a-time.html"><a href="graphing-one-variable-at-a-time.html#skewed-right-distributions"><i class="fa fa-check"></i><b>8.2</b> Skewed Right Distributions</a></li>
<li class="chapter" data-level="8.3" data-path="graphing-one-variable-at-a-time.html"><a href="graphing-one-variable-at-a-time.html#skewed-left-distributions"><i class="fa fa-check"></i><b>8.3</b> Skewed Left Distributions</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="graphing-relationships.html"><a href="graphing-relationships.html"><i class="fa fa-check"></i><b>9</b> Graphing Relationships</a><ul>
<li class="chapter" data-level="9.1" data-path="graphing-relationships.html"><a href="graphing-relationships.html#bivariate-graphing"><i class="fa fa-check"></i><b>9.1</b> Bivariate Graphing</a></li>
<li class="chapter" data-level="9.2" data-path="graphing-relationships.html"><a href="graphing-relationships.html#multivariate-graphing"><i class="fa fa-check"></i><b>9.2</b> Multivariate Graphing</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="11" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>11</b> Analysis of Variance</a><ul>
<li class="chapter" data-level="11.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-anova-f-test"><i class="fa fa-check"></i><b>11.1</b> The ANOVA F-Test</a></li>
<li class="chapter" data-level="11.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-idea-behind-the-anova-f-test"><i class="fa fa-check"></i><b>11.2</b> The Idea Behind the ANOVA F-Test</a></li>
<li class="chapter" data-level="11.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#finding-the-p-value"><i class="fa fa-check"></i><b>11.3</b> Finding the P-Value</a></li>
<li class="chapter" data-level="11.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#making-conclusions-in-context"><i class="fa fa-check"></i><b>11.4</b> Making Conclusions in Context</a></li>
<li class="chapter" data-level="11.5" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#post-hoc-tests"><i class="fa fa-check"></i><b>11.5</b> Post Hoc Tests</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="chi-square-test-of-independence.html"><a href="chi-square-test-of-independence.html"><i class="fa fa-check"></i><b>12</b> Chi-Square Test of Independence</a><ul>
<li class="chapter" data-level="12.1" data-path="chi-square-test-of-independence.html"><a href="chi-square-test-of-independence.html#exploratory-analysis"><i class="fa fa-check"></i><b>12.1</b> Exploratory Analysis</a></li>
<li class="chapter" data-level="12.2" data-path="chi-square-test-of-independence.html"><a href="chi-square-test-of-independence.html#the-chi-square-test-for-independence"><i class="fa fa-check"></i><b>12.2</b> The Chi-Square Test for Independence</a></li>
<li class="chapter" data-level="12.3" data-path="chi-square-test-of-independence.html"><a href="chi-square-test-of-independence.html#the-idea-of-the-chi-square-test"><i class="fa fa-check"></i><b>12.3</b> The Idea of the Chi-Square Test</a></li>
<li class="chapter" data-level="12.4" data-path="chi-square-test-of-independence.html"><a href="chi-square-test-of-independence.html#post-hoc-tests-1"><i class="fa fa-check"></i><b>12.4</b> Post Hoc Tests</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="correlation-coefficient.html"><a href="correlation-coefficient.html"><i class="fa fa-check"></i><b>13</b> Correlation Coefficient</a><ul>
<li class="chapter" data-level="13.1" data-path="correlation-coefficient.html"><a href="correlation-coefficient.html#interpreting-the-scatterplot"><i class="fa fa-check"></i><b>13.1</b> Interpreting the scatterplot</a></li>
<li class="chapter" data-level="13.2" data-path="correlation-coefficient.html"><a href="correlation-coefficient.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>13.2</b> The Correlation Coefficient</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="moderation.html"><a href="moderation.html"><i class="fa fa-check"></i><b>14</b> Moderation</a></li>
<li class="chapter" data-level="15" data-path="linear-regression-summarizing-the-pattern-of-the-data-with-a-line.html"><a href="linear-regression-summarizing-the-pattern-of-the-data-with-a-line.html"><i class="fa fa-check"></i><b>15</b> Linear Regression: Summarizing the Pattern of the Data with a Line</a></li>
<li class="chapter" data-level="16" data-path="sampling-and-designing-studies.html"><a href="sampling-and-designing-studies.html"><i class="fa fa-check"></i><b>16</b> Sampling and Designing Studies</a><ul>
<li class="chapter" data-level="16.1" data-path="sampling-and-designing-studies.html"><a href="sampling-and-designing-studies.html#designing-studies"><i class="fa fa-check"></i><b>16.1</b> Designing Studies</a></li>
<li class="chapter" data-level="16.2" data-path="sampling-and-designing-studies.html"><a href="sampling-and-designing-studies.html#identifying-study-design"><i class="fa fa-check"></i><b>16.2</b> Identifying Study Design</a></li>
<li class="chapter" data-level="16.3" data-path="sampling-and-designing-studies.html"><a href="sampling-and-designing-studies.html#experiments-vs.observational-studies"><i class="fa fa-check"></i><b>16.3</b> Experiments vs. Observational Studies</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="confounding-and-multivariate-models.html"><a href="confounding-and-multivariate-models.html"><i class="fa fa-check"></i><b>17</b> Confounding and Multivariate Models</a></li>
<li class="chapter" data-level="18" data-path="poster-presentation.html"><a href="poster-presentation.html"><i class="fa fa-check"></i><b>18</b> Poster Presentation</a></li>
<li class="chapter" data-level="" data-path="copyright.html"><a href="copyright.html"><i class="fa fa-check"></i>Copyright</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><a href="http://www.wesleyan.edu/qac/curriculum/resources/index.html">Passion Driven Statistics</a></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1">
<h1><span class="header-section-number">10</span> Hypothesis Testing</h1>
<p>Please watch the <a href="http://passiondrivenstatistics.com/2015/07/15/chapter-10/">Chapter 10 video</a>.</p>
<p>Thus far, we have focused on descriptive statistics. Through our examination of frequency distributions, graphical representations of our variables, and calculations of center and spread, the goal has been to describe and summarize data. Now you will be introduced to inferential statistics. In addition to describing data, inferential statistics allow us to directly test our hypothesis by evaluating (based on a sample) our research question with the goal of generalizing the results to the larger population from which the sample was drawn.</p>
<p>Hypothesis testing is one of the most important inferential tools of application of statistics to real life problems. It is used when we need to make decisions concerning populations on the basis of only sample information. A variety of statistical tests are used to arrive at these decisions (e.g. Analysis of Variance, Chi-Square Test of Independence, etc.). Steps involved in hypothesis testing include specifying the null (<span class="math inline">\(H_0\)</span>) and alternate (<span class="math inline">\(H_a\)</span> or <span class="math inline">\(H_1\)</span>) hypotheses; choosing a sample; assessing the evidence; and making conclusions.</p>
<p><strong>Statistical hypothesis testing is defined as assessing evi- dence provided by the data in favor of or against each hypothesis about the population.</strong></p>
<p>The purpose of this section is to build your understanding about how statistical hypothesis testing works.</p>
<p><strong>Example:</strong></p>
<p>To test what I have read in the scientific literature, I decide to evaluate whether or not there is a difference in smoking quantity (i.e. number of cigarettes smoked) according to whether or not an individual has a diagnosis of major depression.</p>
<p>Let’s analyze this example using the 4 steps: Specifying the null (<span class="math inline">\(H_0\)</span>) and alternate (<span class="math inline">\(H_a\)</span>) hypotheses; choosing a sample; assessing the evidence; and making conclusions.</p>
<p>There are two opposing hypotheses for this question:</p>
<ul>
<li>There is no difference in smoking quantity between people with and without depression.</li>
<li>There is a difference in smoking quantity between people with and without depression.</li>
</ul>
<p>The first hypothesis (aka null hypothesis) basically says nothing special is going on between smoking and depression. In other words, that they are unrelated to one another. The second hypothesis (aka the alternate hypothesis) says that there is a relationship and allows that the difference in smoking between those individuals with and without depression could be in either direction (i.e. individuals with depression may smoke more than individuals without depression or they may smoke less).</p>
<p><em>1. Choosing a Sample:</em></p>
<p>I chose the NESARC, a representative sample of 43,093 non-institutionalized adults in the U.S. As I am interested in evaluating these hypotheses only among individuals who are smokers and who are younger (rather than older) adults, I subset the NESARC data to individuals that are 1) current daily smokers (i.e. smoked in the past year <code>CHECK321 ==1</code>, smoked over 100 cigarettes <code>S3AQ1A ==1</code>, typically smoked every day <code>S3AQ3B1 == 1</code>) are 2) between the ages 18 and 25. This sample (<span class="math inline">\(n=1320\)</span>) showed the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># See Chapter 7 for the creation of nesarc</span>
<span class="kw">summary</span>(nesarc)</code></pre></div>
<pre><code>            Ethnicity        Age              MajorDepression
 Caucasian       :849   Min.   :18.00   No Depression :965   
 African American:170   1st Qu.:20.00   Yes Depression:355   
 Native American : 30   Median :22.00                        
 Asian           : 47   Mean   :21.61                        
 Hispanic        :224   3rd Qu.:24.00                        
                        Max.   :25.00                        
                                                             
              TobaccoDependence DailyCigsSmoked     Sex     
 No Nicotine Dependence:521     Min.   : 1.00   Female:646  
 Nicotine Dependence   :799     1st Qu.: 7.00   Male  :674  
                                Median :10.00               
                                Mean   :13.36               
                                3rd Qu.:20.00               
                                Max.   :98.00               
                                NA&#39;s   :5                   
                        AlcoholAD   NumberNicotineSymptoms     DCScat   
 No Alcohol                  :768   Min.   : 0.00          (0,5]  :249  
 Alcohol Abuse               :242   1st Qu.: 9.00          (5,10] :477  
 Alcohol Dependence          : 62   Median :17.00          (10,15]:134  
 Alcohol Abuse and Dependence:248   Mean   :19.61          (15,20]:368  
                                    3rd Qu.:29.25          (20,98]: 87  
                                    Max.   :65.00          NA&#39;s   :  5  
                                                                        </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tapply</span>(nesarc$DailyCigsSmoked, <span class="kw">list</span>(nesarc$MajorDepression), mean, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code> No Depression Yes Depression 
      13.16632       13.90368 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tapply</span>(nesarc$DailyCigsSmoked, <span class="kw">list</span>(nesarc$MajorDepression), sd, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code> No Depression Yes Depression 
      8.460312       9.162474 </code></pre>
<ul>
<li><p>Young adult, daily smokers with depression smoked an average of 13.9 cigarettes per day (SD = 9.2).</p></li>
<li><p>Young adult, daily smokers without depression smoked an average of 13.2 cigarettes per day (SD = 8.5).</p></li>
</ul>
<p>While it is true that 13.9 cigarettes per day are more than 13.2 cigarettes per day, it is not at all clear that this is a large enough difference to reject the null hypothesis.</p>
<p><em>2. Assessing the Evidence:</em></p>
<p>In order to assess whether the data provide strong enough evidence against the null hypothesis (i.e. against the claim that there is no relationship between smoking and depression), we need to ask ourselves: How surprising is it to get a difference of 0.7373626 cigarettes smoked per day between our two groups (depression vs. no depression) assuming that the null hypothesis is true (i.e. there is no relationship between smoking and depression).</p>
<p>This is the step where we calculate how likely it is to get data like that observed when <span class="math inline">\(H_0\)</span> is true. In a sense, this is the heart of the process, since we draw our conclusions based on this probability.</p>
<p>It turns out that the probability that we’ll get a difference of this size in the mean number of cigarettes smoked in a random sample of 1320 participants is 0.1711689 (do not worry about how this was calculated at this point).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(nesarc$DailyCigsSmoked ~<span class="st"> </span>nesarc$MajorDepression, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>
    Two Sample t-test

data:  nesarc$DailyCigsSmoked by nesarc$MajorDepression
t = -1.3692, df = 1313, p-value = 0.1712
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -1.7938413  0.3191162
sample estimates:
 mean in group No Depression mean in group Yes Depression 
                    13.16632                     13.90368 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pvalue &lt;-<span class="st"> </span><span class="kw">t.test</span>(nesarc$DailyCigsSmoked ~<span class="st"> </span>nesarc$MajorDepression, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)$p.value
pvalue</code></pre></div>
<pre><code>[1] 0.1711689</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Or</span>
<span class="kw">summary</span>(<span class="kw">aov</span>(DailyCigsSmoked ~<span class="st"> </span>MajorDepression, <span class="dt">data =</span> nesarc))</code></pre></div>
<pre><code>                  Df Sum Sq Mean Sq F value Pr(&gt;F)
MajorDepression    1    140  140.41   1.875  0.171
Residuals       1313  98336   74.89               
5 observations deleted due to missingness</code></pre>
<p>Well, we found that if the null hypothesis were true (i.e. there is no association) there is a probability of 0.1711689 of observing data like that observed.</p>
<p>Now you have to decide…</p>
<p>Do you think that a probability of 0.1711689 makes our data rare enough (surprising enough) under the null hypothesis so that the fact that we did observe it is enough evidence to reject the null hypothesis?</p>
<p>Or do you feel that a probability of 0.1711689 means that data like we observed are not very likely when the null hypothesis is true (not unlikely enough to conclude that getting such data is sufficient evidence to reject the null hypothesis).</p>
<p>Basically, this is your decision. However, it would be nice to have some kind of guideline about what is generally considered surprising enough.</p>
<p>The reason for using an inferential test is to get a <strong>p-value</strong>. The p-value determines whether or not we reject the null hypothesis. The p-value provides an estimate of how often we would get the obtained result by chance if in fact the null hypothesis were true. In statistics, a result is called statistically significant if it is unlikely to have occurred by chance alone. If the p-value is small (i.e. less than 0.05), this suggests that it is likely (more than 95% likely) that the association of interest would be present following repeated samples drawn from the population (aka a sampling distribution).</p>
<p>If this probability is very small, then that means that it would be very surprising to get data like that observed if the null hypothesis were true. The fact that we did not observe such data is therefore evidence supporting the null hypothesis, and we should accept it. On the other hand, if this probability were very small, this means that observing data like that observed is surprising if the null hypothesis were true, so the fact that we observed such data provides evidence against the null hypothesis (i.e. suggests that there is an association between smoking and depression). This crucial probability, therefore, has a special name. It is called the p-value of the test.</p>
<p>In our examples, the p-value was given to you (and you were reassured that you didn’t need to worry about how these were derived):</p>
<ul>
<li>P-Value = 0.1711689</li>
</ul>
<p>Obviously, the smaller the p-value, the more surprising it is to get data like ours when the null hypothesis is true, and therefore the stronger the evidence the data provide against the null. Looking at the p-value in our example we see that there is not adequate evidence to reject the null hypothesis. <strong>In other words, we fail to reject the null hypothesis that there is no association between smoking and depression.</strong></p>
<p>Since our conclusion is based on how small the p-value is, or in other words, how surprising our data are when the null hypothesis (<span class="math inline">\(H_0\)</span>) is true, it would be nice to have some kind of guideline or cutoff that will help determine how small the p-value must be, or how “rare” (unlikely) our data must be when <span class="math inline">\(H_0\)</span> is true, for us to conclude that we have enough evidence to reject <span class="math inline">\(H_0\)</span>. This cutoff exists, and because it is so important, it has a special name. It is called the significance level of the test and is usually denoted by the Greek letter <span class="math inline">\(\alpha\)</span>. The most commonly used significance level is <span class="math inline">\(\alpha=0.05\)</span> (or 5%). This means that:</p>
<ul>
<li><p>if the p-value <span class="math inline">\(&lt; \alpha\)</span> (usually 0.05), then the data we got is considered to be “rare (or surprising) enough” when <span class="math inline">\(H_0\)</span> is true, and we say that the data provide significant evidence against <span class="math inline">\(H_0\)</span>, so we reject <span class="math inline">\(H_0\)</span> and accept <span class="math inline">\(H_a\)</span>.</p></li>
<li><p>if the p-value <span class="math inline">\(&gt; \alpha\)</span> (usually 0.05), then our data are not considered to be “surprising enough” when <span class="math inline">\(H_0\)</span> is true, and we say that our data do not provide enough evidence to reject <span class="math inline">\(H_0\)</span> (or, equivalently, that the data do not provide enough evidence to accept <span class="math inline">\(H_a\)</span>).</p></li>
</ul>
<p>Although you will <strong>always be interpreting the p-value</strong> for a statistical test, the specific statistical test that you will use to evaluate your hypotheses depends on the type of explanatory and response variables that you have.</p>
<p><strong>Bivariate Statistical Tools:</strong></p>
<ul>
<li><span class="math inline">\(C \rightarrow Q\)</span> Analysis of Variance (ANOVA)</li>
<li><span class="math inline">\(C \rightarrow C\)</span> Chi-Square Test of Independence (<span class="math inline">\(\chi^2\)</span>)</li>
<li><span class="math inline">\(Q \rightarrow Q\)</span> Correlation Coefficient (r)</li>
<li><span class="math inline">\(Q \rightarrow C\)</span> Logistic regression</li>
</ul>
<p><strong>The Big Idea Behind Inference</strong></p>
<p>A <strong>sampling distribution</strong> is a distribution of all possible samples (of a given size) that could be drawn from the population. If you have a sampling distribution meant to estimate a mean (e.g. the average number of cigarettes smoked in a population), this would be represented as a distribution of frequencies of mean number of cigarettes for consecutive samples drawn from the population. Although we ultimately rely on only one sample, if that sample is representative of the larger population, inferential statistical tests allow us to estimate (with different levels of certainty) a mean (or other parameter such as a standard deviation, proportion, etc.) for the entire population. This idea is the foundation for each of the inferential tools that you will be using this semester.</p>
<hr />

</div>
            </section>

          </div>
        </div>
      </div>
<a href="graphing-relationships.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analysis-of-variance.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
